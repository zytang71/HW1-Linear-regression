import io
import json
from dataclasses import dataclass

import numpy as np
import pandas as pd
import streamlit as st
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
import matplotlib.font_manager as fm

st.set_page_config(page_title="ç°¡å–®ç·šæ€§å›æ­¸ï½œCRISP-DM æ•™å­¸", page_icon="ğŸ“ˆ", layout="wide")

# ========= å­—å‹è¨­å®šï¼ˆè§£æ±ºäº‚ç¢¼ï¼‰ =========
# å˜—è©¦ä½¿ç”¨å¸¸è¦‹ä¸­æ–‡å­—å‹ï¼Œè‹¥æ‰¾ä¸åˆ°å‰‡é€€å›è‹±æ–‡å­—å‹
font_candidates = ["Microsoft JhengHei", "PingFang TC", "Noto Sans CJK TC", "SimHei", "Heiti TC", "Arial Unicode MS", "DejaVu Sans"]
available_fonts = [f for f in font_candidates if f in [font.name for font in fm.fontManager.ttflist]]
chosen_font = available_fonts[0] if available_fonts else "DejaVu Sans"

plt.rcParams["font.sans-serif"] = [chosen_font]
plt.rcParams["axes.unicode_minus"] = False

# =============================
# Sidebar â€” ä½¿ç”¨è€…å¯èª¿åƒæ•¸
# =============================
st.sidebar.header("è³‡æ–™ç”Ÿæˆèˆ‡å¯¦é©—è¨­å®š")
with st.sidebar:
    st.markdown("èª¿æ•´ä¸‹åˆ—åƒæ•¸ï¼Œå‹•æ…‹ç”¢ç”Ÿ y = aÂ·x + b + noise çš„è³‡æ–™é›†ã€‚")
    a = st.slider("æ–œç‡ a", min_value=-10.0, max_value=10.0, value=2.0, step=0.1)
    b = st.slider("æˆªè· b", min_value=-50.0, max_value=50.0, value=1.0, step=0.5)
    n_points = st.slider("è³‡æ–™é»æ•¸ (n)", min_value=10, max_value=5000, value=200, step=10)
    x_min, x_max = st.slider("x ç¯„åœ", min_value=-100.0, max_value=100.0, value=(-5.0, 5.0), step=0.5)
    noise_std = st.slider("é›œè¨Šæ¨™æº–å·® (Ïƒ)", min_value=0.0, max_value=50.0, value=2.0, step=0.1)
    test_size = st.slider("æ¸¬è©¦é›†æ¯”ä¾‹", min_value=0.05, max_value=0.95, value=0.2, step=0.05)
    random_state = st.number_input("éš¨æ©Ÿç¨®å­ (random_state)", min_value=0, value=42, step=1)

    st.divider()
    st.markdown(
    """**æ•™å­¸æç¤º Promptï¼ˆå¯ç·¨è¼¯ï¼‰**ï¼š
    > ä»¥ç°¡å–®ç·šæ€§å›æ­¸ç‚ºä¾‹ï¼Œä¾ CRISP-DM æ­¥é©Ÿèªªæ˜ä¸¦ç¤ºç¯„ï¼š
    > åœ¨æŒ‡å®š aã€b èˆ‡é›œè¨Šåƒæ•¸ä¸‹ï¼Œç”¢ç”Ÿè³‡æ–™ã€åˆ‡åˆ†è¨“ç·´/æ¸¬è©¦ã€
    > å»ºç«‹æ¨¡å‹ã€è¨ˆç®— MSE èˆ‡ RÂ²ã€è¦–è¦ºåŒ–è¿´æ­¸ç·šèˆ‡æ®˜å·®ï¼Œ
    > æœ€å¾Œæä¾›å¯ä¸‹è¼‰çš„è³‡æ–™èˆ‡æ¨¡å‹ä¿‚æ•¸ã€‚"""
    )    
    user_prompt = st.text_area("Promptï¼ˆå¯åšä½ çš„å­¸ç¿’ç›®æ¨™æˆ–ä»»å‹™èªªæ˜ï¼‰", value="è«‹ç¤ºç¯„ CRISP-DM æµç¨‹ï¼Œä¸¦ç”¨ç°¡å–®ç·šæ€§å›æ­¸è§£é‡‹è³‡æ–™èˆ‡æ¨¡å‹çš„é—œä¿‚ã€‚", height=100)

# =============================
# 1) Business Understanding
# =============================
st.title("ğŸ“ˆ ç°¡å–®ç·šæ€§å›æ­¸ï¼ˆCRISPâ€‘DM æ•™å­¸äº’å‹•ç¶²é ï¼‰")

st.markdown("""
æœ¬ App ä»¥åˆæˆè³‡æ–™æ¨¡æ“¬çœŸå¯¦ä¸–ç•Œä¸­ **å–®ä¸€è‡ªè®Šæ•¸ x èˆ‡ç›®æ¨™ y** çš„ç·šæ€§é—œä¿‚ï¼š

$$y = a\,x + b + \epsilon,\quad \epsilon \sim \mathcal{N}(0,\sigma^2)$$

ä½ å¯ä»¥é€éå´é‚Šæ¬„èª¿æ•´ \(a\)ã€\(b\)ã€è³‡æ–™é»æ•¸ï¼ˆnï¼‰ã€å™ªè²å¼·åº¦ï¼ˆ\(\sigma\)ï¼‰èˆ‡ x ç¯„åœï¼Œè§€å¯Ÿ**è³‡æ–™åˆ†å¸ƒ**èˆ‡**æ¨¡å‹è¡¨ç¾**å¦‚ä½•è®ŠåŒ–ï¼Œä¸¦å°æ‡‰åˆ° CRISPâ€‘DM å„æ­¥é©Ÿã€‚
""")

with st.expander("CRISPâ€‘DM 1 â”€ Business Understandingï¼ˆæ¥­å‹™ç†è§£ï¼‰", expanded=True):
    st.write(
        "åœ¨è¨±å¤šæƒ…å¢ƒä¸‹ï¼Œæˆ‘å€‘å¸Œæœ›ç”¨ä¸€å€‹ç°¡å–®å¯è§£é‡‹çš„æ¨¡å‹ä¾†é æ¸¬èˆ‡è§£é‡‹ y å° x çš„ä¾å­˜é—œä¿‚ï¼Œä¾‹å¦‚åƒ¹æ ¼å°å°ºå¯¸ã€æˆç¸¾å°å­¸ç¿’æ™‚æ•¸ã€ç”¢å‡ºå°æŠ•æŠ•å…¥é‡ç­‰ã€‚æœ¬ç¤ºç¯„çš„å•†æ¥­/ç ”ç©¶ç›®æ¨™æ˜¯ï¼šçµ¦å®š xï¼Œå»ºç«‹èƒ½é æ¸¬ y ä¸”å…·å¯è§£é‡‹æ€§çš„æ¨¡å‹ã€‚")
    st.info(f"ä½ çš„å­¸ç¿’/ä»»å‹™ Promptï¼š{user_prompt}")

# =============================
# 2) Data Understanding
# =============================
# ç”¢ç”Ÿè³‡æ–™
rng = np.random.default_rng(seed=int(random_state))
X = rng.uniform(low=x_min, high=x_max, size=n_points)
noise = rng.normal(loc=0.0, scale=noise_std, size=n_points)
y = a * X + b + noise

# çµ„æˆ DataFrame æ–¹ä¾¿æª¢è¦–
raw_df = pd.DataFrame({"x": X, "y": y})

with st.expander("CRISPâ€‘DM 2 â”€ Data Understandingï¼ˆè³‡æ–™ç†è§£ï¼‰", expanded=True):
    c1, c2 = st.columns([2, 1])
    with c1:
        st.subheader("è³‡æ–™é è¦½")
        st.dataframe(raw_df.head(20), use_container_width=True)
    with c2:
        st.subheader("åŸºæœ¬çµ±è¨ˆ")
        st.json({
            "x": {
                "min": float(np.min(X)),
                "max": float(np.max(X)),
                "mean": float(np.mean(X)),
                "std": float(np.std(X, ddof=1)),
            },
            "y": {
                "min": float(np.min(y)),
                "max": float(np.max(y)),
                "mean": float(np.mean(y)),
                "std": float(np.std(y, ddof=1)),
            },
            "true_params": {"a": float(a), "b": float(b), "noise_std": float(noise_std)},
        })

    st.caption("èªªæ˜ï¼šæ­¤éšæ®µé‡é»åœ¨æ–¼ç†è§£æ¬„ä½æ„ç¾©èˆ‡åˆ†å¸ƒç‰¹æ€§ï¼Œä¸¦æª¢æŸ¥æ˜¯å¦æœ‰æ˜é¡¯ç•°å¸¸å€¼æˆ–è³‡æ–™ä¸è¶³ã€‚")

# =============================
# 3) Data Preparation
# =============================
with st.expander("CRISPâ€‘DM 3 â”€ Data Preparationï¼ˆè³‡æ–™æº–å‚™ï¼‰", expanded=True):
    st.write("æ­¤è™•ç¤ºç¯„æœ€å°åŒ–çš„å‰è™•ç†ï¼šéš¨æ©Ÿåˆ‡åˆ†è¨“ç·´/æ¸¬è©¦é›†ã€‚è‹¥æ˜¯çœŸå¯¦è³‡æ–™ï¼Œé‚„å¯èƒ½åŒ…å«ï¼šç¼ºå¤±å€¼è™•ç†ã€ç•°å¸¸å€¼è™•ç†ã€ç‰¹å¾µå·¥ç¨‹ã€æ¨™æº–åŒ–/æ­£è¦åŒ–ç­‰ã€‚")

    X_2d = X.reshape(-1, 1)
    X_train, X_test, y_train, y_test = train_test_split(
        X_2d, y, test_size=test_size, random_state=int(random_state)
    )

    st.code(
        """
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=..., random_state=...)
        """,
        language="python",
    )

    st.success(f"è³‡æ–™åˆ‡åˆ†å®Œæˆï¼štrain = {len(X_train)}, test = {len(X_test)}ï¼ˆæ¸¬è©¦æ¯”ä¾‹ {test_size:.2f}ï¼‰")

# =============================
# 4) Modeling
# =============================
with st.expander("CRISPâ€‘DM 4 â”€ Modelingï¼ˆå»ºæ¨¡ï¼‰", expanded=True):
    st.write("æˆ‘å€‘ä½¿ç”¨ `sklearn.linear_model.LinearRegression` é€²è¡Œæœ€å°å¹³æ–¹æ³•ä¼°è¨ˆã€‚")

    model = LinearRegression()
    model.fit(X_train, y_train)

    pred_train = model.predict(X_train)
    pred_test = model.predict(X_test)

    learned_a = float(model.coef_[0])
    learned_b = float(model.intercept_)

    st.json({"learned_params": {"a_hat": learned_a, "b_hat": learned_b}})

    st.code(
        """
from sklearn.linear_model import LinearRegression
model = LinearRegression().fit(X_train, y_train)
a_hat = model.coef_[0]
b_hat = model.intercept_
        """,
        language="python",
    )

# =============================
# 5) Evaluation
# =============================
with st.expander("CRISPâ€‘DM 5 â”€ Evaluationï¼ˆè©•ä¼°ï¼‰", expanded=True):
    mse_train = mean_squared_error(y_train, pred_train)
    r2_train = r2_score(y_train, pred_train)
    mse_test = mean_squared_error(y_test, pred_test)
    r2_test = r2_score(y_test, pred_test)

    st.subheader("æŒ‡æ¨™ï¼ˆè¶Šå°è¶Šå¥½/è¶Šå¤§è¶Šå¥½ï¼‰")
    mcol1, mcol2, mcol3, mcol4 = st.columns(4)
    mcol1.metric("MSE (train)", f"{mse_train:.4f}")
    mcol2.metric("RÂ² (train)", f"{r2_train:.4f}")
    mcol3.metric("MSE (test)", f"{mse_test:.4f}")
    mcol4.metric("RÂ² (test)", f"{r2_test:.4f}")

    st.caption("RÂ² âˆˆ [0, 1]ï¼Œè¶Šæ¥è¿‘ 1 ä»£è¡¨è§£é‡‹åŠ›è¶Šå¥½ï¼›MSE è¶Šå°ä»£è¡¨èª¤å·®è¶Šå°ã€‚å› è³‡æ–™å«å™ªï¼Œä¼°è¨ˆåƒæ•¸å¯èƒ½èˆ‡çœŸå¯¦ aã€b æœ‰å·®è·ã€‚")

# =============================
# è¦–è¦ºåŒ–ï¼šè³‡æ–™é»èˆ‡è¿´æ­¸ç·šã€æ®˜å·®åœ–
# =============================
with st.expander("è¦–è¦ºåŒ–ï¼ˆè³‡æ–™é»ã€æ¨¡å‹èˆ‡æ®˜å·®ï¼‰", expanded=True):
    import matplotlib.pyplot as plt

    # ä¾ x ç¯„åœç•«é æ¸¬ç·š
    xx = np.linspace(x_min, x_max, 200).reshape(-1, 1)
    yy = model.predict(xx)

    fig1, ax1 = plt.subplots(figsize=(7, 4))
    ax1.scatter(X_train, y_train, alpha=0.6, label="train")
    ax1.scatter(X_test, y_test, alpha=0.8, label="test", marker="s")
    ax1.plot(xx, yy, linewidth=2, label="prediction")
    ax1.set_title("è³‡æ–™é»èˆ‡è¿´æ­¸ç·š")
    ax1.set_xlabel("x")
    ax1.set_ylabel("y")
    ax1.legend()
    st.pyplot(fig1)

    # æ®˜å·®åœ–ï¼ˆtestï¼‰
    residuals = y_test - pred_test
    fig2, ax2 = plt.subplots(figsize=(7, 4))
    ax2.scatter(pred_test, residuals, alpha=0.8)
    ax2.axhline(0, linestyle="--")
    ax2.set_title("æ®˜å·® vs. é æ¸¬å€¼ï¼ˆæ¸¬è©¦é›†ï¼‰")
    ax2.set_xlabel("y_pred")
    ax2.set_ylabel("residual = y_true - y_pred")
    st.pyplot(fig2)

# =============================
# 6) Deployment + ä¸‹è¼‰æˆæœ
# =============================
with st.expander("CRISPâ€‘DM 6 â”€ Deploymentï¼ˆéƒ¨ç½²/ç”¢å‡ºï¼‰", expanded=True):
    st.write("åœ¨æ­£å¼ç’°å¢ƒä¸­ï¼Œéƒ¨ç½²å¯èƒ½æ˜¯æä¾› APIã€å„€è¡¨æ¿æˆ–æ‰¹æ¬¡é æ¸¬ã€‚æœ¬ç¤ºç¯„æä¾›å¯ä¸‹è¼‰çš„è³‡æ–™èˆ‡æ¨¡å‹ä¿‚æ•¸ï¼Œæ–¹ä¾¿ç´€éŒ„æˆ–å¾ŒçºŒæ¯”å°ã€‚")

    # å¯ä¸‹è¼‰è³‡æ–™ CSV
    csv_buf = io.StringIO()
    raw_df.to_csv(csv_buf, index=False)
    st.download_button("ä¸‹è¼‰åˆæˆè³‡æ–™ CSV", data=csv_buf.getvalue(), file_name="synthetic_linear_data.csv", mime="text/csv")

    # å¯ä¸‹è¼‰æ¨¡å‹ä¿‚æ•¸ JSON
    model_artifact = {
        "a_hat": learned_a,
        "b_hat": learned_b,
        "metrics": {
            "mse_train": float(mse_train),
            "r2_train": float(r2_train),
            "mse_test": float(mse_test),
            "r2_test": float(r2_test),
        },
        "data_gen_params": {
            "a": float(a),
            "b": float(b),
            "noise_std": float(noise_std),
            "n_points": int(n_points),
            "x_range": [float(x_min), float(x_max)],
            "test_size": float(test_size),
            "random_state": int(random_state),
        },
    }
    st.download_button(
        "ä¸‹è¼‰æ¨¡å‹æ‘˜è¦ JSON",
        data=json.dumps(model_artifact, ensure_ascii=False, indent=2),
        file_name="linear_regression_summary.json",
        mime="application/json",
    )

st.divider()
st.markdown("""
### å‚™è¨»
- æœ¬ App èšç„¦æ–¼**ç°¡å–®ç·šæ€§å›æ­¸**ï¼ˆå–®ä¸€ç‰¹å¾µï¼‰ã€‚å¤šå…ƒç·šæ€§å›æ­¸å¯æ“´å……ç‚ºå¤šå€‹ç‰¹å¾µæ¬„ä½èˆ‡çŸ©é™£ Xã€‚
- çœŸå¯¦ä¸–ç•Œæœƒéœ€è¦æ›´å®Œæ•´çš„è³‡æ–™æª¢æŸ¥ã€ç‰¹å¾µå·¥ç¨‹èˆ‡æ¨¡å‹æ¯”è¼ƒã€‚
- ä½ å¯å°‡æ­¤ App ä½œç‚º CRISPâ€‘DM çš„æ•™å­¸ Labï¼Œè®“å­¸ç”Ÿé€šéæ“ä½œç†è§£æ¯ä¸€æ­¥çš„æ„ç¾©èˆ‡å°çµæœçš„å½±éŸ¿ã€‚
""")